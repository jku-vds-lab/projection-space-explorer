{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgn2gif import chess\n",
    "import numpy as np\n",
    "from openTSNE import TSNE\n",
    "from openTSNE.callbacks import ErrorApproximations\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import interpolate\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "FILE_NAME = '/mnt/d/Work/CG Institute/chess/lichess data/lichess_db_standard_rated_2021-08.pgn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_vector(state):\n",
    "    piece_dict = {\n",
    "        'wr': [1,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "        'wn': [0,1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "        'wb': [0,0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "        'wk': [0,0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "        'wq': [0,0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "        'wp': [0,0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "        'br': [0,0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "        'bn': [0,0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "        'bb': [0,0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "        'bk': [0,0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "        'bq': [0,0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "        'bp': [0,0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "        '':   [0,0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "    }    \n",
    "    state_list = list(state.values())    \n",
    "    vector = []\n",
    "    for piece in state_list:\n",
    "        vector.append(piece_dict[piece])\n",
    "    return np.array(vector).ravel()\n",
    "\n",
    "def vector_to_state(vector):\n",
    "    vec_dict = {\n",
    "        '1000000000000': \"wr\",\n",
    "        '0100000000000': \"wn\",\n",
    "        '0010000000000': \"wb\",\n",
    "        '0001000000000': \"wk\",\n",
    "        '0000100000000': \"wq\",\n",
    "        '0000010000000': \"wp\",\n",
    "        '0000001000000': \"br\",\n",
    "        '0000000100000': \"bn\",\n",
    "        '0000000010000': \"bb\",\n",
    "        '0000000001000': \"bk\",\n",
    "        '0000000000100': \"bq\",\n",
    "        '0000000000010': \"bp\",\n",
    "        '0000000000001': \"\"\n",
    "    }\n",
    "    \n",
    "    return vec_dict[vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_to_vectors(file):\n",
    "    game = chess.ChessGame(file)\n",
    "    vectors = [state_to_vector(game.state)]\n",
    "    while not game.is_finished:\n",
    "        try:\n",
    "            game.next()\n",
    "        except:\n",
    "            pass\n",
    "        vectors.append(state_to_vector(game.state))\n",
    "    return np.stack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moves_from_pgn(pgn, keep_x=False):\n",
    "    with open(pgn) as p:\n",
    "        data = p.read()\n",
    "        data = re.sub(r'\\{.*?\\}', '', data) # Removes pgn comments\n",
    "        data = re.sub(r'\\[.*?\\]', '', data) # removes metadata\n",
    "        moves = re.findall(\n",
    "            r'[a-h]x?[a-h]?[1-8]=?[BKNRQ]?|O-O-?O?|[BKNRQ][a-h1-8]?[a-h1-8]?x?[a-h][1-8]',\n",
    "            data)\n",
    "        if keep_x:\n",
    "            return moves\n",
    "        else:\n",
    "            return [move.replace('x', '') for move in moves]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method for retrieving all metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_from_pgn(pgn):\n",
    "    with open(pgn) as p:\n",
    "        data = p.read()\n",
    "        \n",
    "        # per mvoe metadata\n",
    "        evals = re.findall(r'\\[%eval (.*?)\\]',data)\n",
    "        clks = re.findall(r'\\[%clk (.*?)\\]',data)\n",
    "        # add metadata for before first move\n",
    "        evals = ['0']+evals\n",
    "        clks = ['0:00:00'] + clks\n",
    "        \n",
    "        # per game metadata\n",
    "        data = re.sub(r'\\{.*?\\}', '', data)  # Removes pgn comments\n",
    "        m = re.findall(r'\\[(.*) \"(.*)\"]',data)\n",
    "        metadata_keys = [i[0] for i in m]\n",
    "        metadata_values = [i[1].replace(',',';') for i in m]\n",
    "        \n",
    "        return dict(zip(metadata_keys, metadata_values)), evals, clks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading\n"
     ]
    }
   ],
   "source": [
    "print(\"start loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract individual games from PGN file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_to_read = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Event \"N/A\"]\n",
      "[Site \"N/A\"]\n",
      "[Date \"??\"]\n",
      "[Round: \"-\"]\n",
      "[White: \"White\"]\n",
      "[Black: \"Black\"]\n",
      "[Result \"*\"]\n",
      "[ECO \"E99\"]\n",
      "[Opening \"King's Indian Defense: Orthodox Variation, Classical System, Traditional Line\"]\n",
      "\n",
      "1. d4 Nf6 2. c4 g6 3. Nc3 Bg7 4. e4 d6 5. Nf3 O-O 6. Be2 e5 7. O-O Nc6 8. d5 Ne7 9. Ne1 Nd7 10. f3 f5\n",
      "3398\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path(\"games\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(FILE_NAME, 'r') as f:\n",
    "    all_games = ''.join([f.readline() for i in range(lines_to_read)])\n",
    "\n",
    "span = 2\n",
    "all_games = all_games.split(\"\\n\\n\")\n",
    "split_games  = [\"\\n\\n\".join(all_games[i:i+span]) for i in range(0, len(all_games), span)]\n",
    "print(split_games[-2])\n",
    "print(len(split_games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter out games without eval score or without clk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only games that contain clk and eval metadata for moves\n",
    "filtered = []\n",
    "for game in split_games:\n",
    "    if '%eval' in game and '%clk' in game:\n",
    "        filtered.append(game)\n",
    "split_games = filtered\n",
    "\n",
    "# sometimes there are individual turns that only have a clk but no eval, discard those games\n",
    "filtered = []\n",
    "for game in split_games:\n",
    "    m = re.findall(r'{ \\[%clk(.*?) (.*?)\\] }', game)\n",
    "    if len(m) == 0:\n",
    "        filtered.append(game)\n",
    "split_games = filtered\n",
    "\n",
    "print(len(split_games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keep n games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_games = 2000\n",
    "split_games = split_games[:n_games]\n",
    "print(len(split_games))\n",
    "print(split_games[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store individual games as PGN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(split_games)):\n",
    "    with open('games/game-{:05d}.pgn'.format(i+1),'w') as f:\n",
    "        f.write(split_games[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "notrandgames = ['games/game-{:05d}.pgn'.format(n+1) for n in range(10000)]\n",
    "print(len(notrandgames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading games from individual PGN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]\n"
     ]
    }
   ],
   "source": [
    "notrandgames_checked = []\n",
    "metadata = []\n",
    "metadata_evals = []\n",
    "metadata_clks = []\n",
    "old_md_keys = None\n",
    "for id, g in enumerate(notrandgames):\n",
    "    try:\n",
    "        game_to_vectors(g)\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        notrandgames_checked.append((id,g))\n",
    "        metadata_dict, evals, clks = get_metadata_from_pgn(g)\n",
    "        # get least common denominator among keys in all samples such that there aren't outlier samples that have more metadata than others\n",
    "        md_keys = [k for k in metadata_dict]\n",
    "        if old_md_keys:\n",
    "            md_keys = list(set(md_keys).intersection(old_md_keys))\n",
    "        old_md_keys = md_keys\n",
    "        metadata.append(metadata_dict)\n",
    "        metadata_evals.append(evals)\n",
    "        metadata_clks.append(clks)\n",
    "        \n",
    "# remove outlier metadata such that only shared metadata among all samples remains\n",
    "for d in metadata:\n",
    "    keys = [k for k in d]\n",
    "    dif = list(set(keys) - set(md_keys))\n",
    "    for k in dif:\n",
    "        d.pop(k)\n",
    "        \n",
    "print(md_keys)\n",
    "print(metadata[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c']\n",
      "{'a': 1, 'b': 2}\n"
     ]
    }
   ],
   "source": [
    "d1 = {'a': 1, 'b': 2, 'c': 3}\n",
    "d2 = {'a': 1, 'b': 2}\n",
    "d1k = [k for k in d1]\n",
    "d2k = [k for k in d2]\n",
    "keys = list(set(d1k).difference(d2k))\n",
    "print(keys)\n",
    "for k in keys:\n",
    "    d1.pop(k)\n",
    "print(d1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_350/3075493226.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# add all games regardless of first move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfirstmoves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_moves_from_pgn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnotrandgames_checked\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfirstmoves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_350/3075493226.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# add all games regardless of first move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfirstmoves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_moves_from_pgn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnotrandgames_checked\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfirstmoves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# add all games regardless of first move\n",
    "firstmoves = [(g[0],get_moves_from_pgn(g[1])[0]) for g in notrandgames_checked]\n",
    "indices = []\n",
    "for idx, fm in firstmoves:\n",
    "    indices.append(idx)\n",
    "games = ['games/game-{:05d}.pgn'.format(n+1) for n in np.array(indices)]\n",
    "game_matrices = [game_to_vectors(g) for g in games]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling an error where the last 2 states of each game are equivalent - remove redundant one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game matrices is num_games * num_turns * 832 \n",
    "for game in range(len(game_matrices)):\n",
    "    # check for each game whether last 2 game states are equivalent\n",
    "    if np.all(game_matrices[game][-2] == game_matrices[game][-1]):\n",
    "        # if so, remove the last state\n",
    "        game_matrices[game] = game_matrices[game][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keep opening moves only\n",
    "using the list of openings that corresponds to the lichess dataset https://github.com/niklasf/chess-openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_a_df = pd.read_csv('ECos/a.tsv', sep='\\t', header=0)\n",
    "eco_b_df = pd.read_csv('ECos/b.tsv', sep='\\t', header=0)\n",
    "eco_c_df = pd.read_csv('ECos/c.tsv', sep='\\t', header=0)\n",
    "eco_d_df = pd.read_csv('ECos/d.tsv', sep='\\t', header=0)\n",
    "eco_e_df = pd.read_csv('ECos/e.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_df = pd.concat([eco_a_df, eco_b_df, eco_c_df, eco_d_df, eco_e_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata[111]['Opening'])\n",
    "moves = eco_df.loc[eco_df['name'] == metadata[111]['Opening'].replace(';',',')]['pgn'].iloc[0]\n",
    "pattern = r'.\\..'\n",
    "print(moves)\n",
    "print(moves.count(' '))\n",
    "moves = (re.sub(pattern, '', moves))\n",
    "print(moves)\n",
    "print(len(moves.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(game_matrices[0])\n",
    "print(metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add ECO category (A,B,C,D,E,F) to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in metadata:\n",
    "    if m['ECO'][0] == 'A':\n",
    "        m['Opening Category'] = 'A - Flank Opening'\n",
    "    elif m['ECO'][0] == 'B':\n",
    "        m['Opening Category'] = 'B - Semi-Open Games other than the French Defense'\n",
    "    elif m['ECO'][0] == 'C':\n",
    "        m['Opening Category'] = 'C - Open Games and the French Defense'\n",
    "    elif m['ECO'][0] == 'D':\n",
    "        m['Opening Category'] = 'D - Closed Games and Semi-Closed Games'\n",
    "    elif m['ECO'][0] == 'E':\n",
    "        m['Opening Category'] = 'E - Indian Defenses'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter games with Openings that don't exist in our ECO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'.\\..'\n",
    "to_delete = []\n",
    "for id, gm in enumerate(game_matrices):\n",
    "    filtered_df = eco_df.loc[eco_df['name'] == metadata[id]['Opening'].replace(';',',')]\n",
    "    if filtered_df.empty:\n",
    "        to_delete += [id]\n",
    "\n",
    "for idx in sorted(to_delete, reverse=True):\n",
    "    del game_matrices[idx]\n",
    "    del metadata[idx]\n",
    "    del metadata_evals[idx]\n",
    "    del metadata_clks[idx]\n",
    "    del games[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using eco dataframe to determine amount n of moves in the corresponding opening, cutting off each game after n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern used to remove turn numbers such that we can determine amount of moves\n",
    "pattern = r'.\\..'\n",
    "for id, gm in enumerate(game_matrices):\n",
    "#     print(metadata[id]['Opening'].replace(';',','))\n",
    "    filtered_df = eco_df.loc[eco_df['name'] == metadata[id]['Opening'].replace(';',',')]\n",
    "    moves = filtered_df['pgn'].iloc[0]\n",
    "    moves = (re.sub(pattern, '', moves))\n",
    "    n_moves = len(moves.split(' '))\n",
    "    # +1 because the 0th is before any moves have happened\n",
    "    game_matrices[id] = game_matrices[id][:n_moves+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(game_matrices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = np.concatenate(game_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "    perplexity=200,\n",
    "    n_jobs=6,\n",
    "    metric='euclidean',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time embedding = tsne.fit(np.array(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_split = np.array_split(embedding, np.add.accumulate([len(l) for l in game_matrices]))[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add empty coordinates for further processing instead of calculating t-sne\n",
    "embedding_split = []\n",
    "for i, game in enumerate(game_matrices):\n",
    "    embedding_split += [[[0, 0] for move in game]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,15))\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.set_aspect(1)\n",
    "# for game in embedding_split[:10]:\n",
    "#     tck, u = interpolate.splprep(game.transpose(), s=0)\n",
    "#     unew = np.arange(0, 1.01, 0.01)\n",
    "#     out = interpolate.splev(unew, tck)\n",
    "#     ax.plot(out[0], out[1], '-r', alpha=0.03, color='red')\n",
    "#     ax.scatter(game[:,0], game[:,1], s=0.1, color='red')\n",
    "# #for game in embedding_split[10:800]:\n",
    "# #    tck, u = interpolate.splprep(game.transpose(), s=0)\n",
    "# #    unew = np.arange(0, 1.01, 0.01)\n",
    "# #    out = interpolate.splev(unew, tck)\n",
    "# #    ax.plot(out[0], out[1], '-r', alpha=0.03, color='blue')\n",
    "# #    ax.scatter(game[:,0], game[:,1], s=0.1, color='blue')\n",
    "# plt.xlim((-40,50));\n",
    "# plt.ylim((-60,40));\n",
    "# #for game in embedding_split[100:]:\n",
    "# #    ax.plot(game[:,0], game[:,1], '-r', alpha=0.1, color='blue')\n",
    "\n",
    "\n",
    "# write header\n",
    "csv = open(\"lichess_tsne.csv\", \"w\")\n",
    "features = \"x,y,line,cp,algo,player,age,\"\n",
    "print(md_keys)\n",
    "features += ','.join(md_keys)\n",
    "features += \",eval,clk,a8,b8,c8,d8,e8,f8,g8,h8,a7,b7,c7,d7,e7,f7,g7,h7,a6,b6,c6,d6,e6,f6,g6,h6,a5,b5,c5,d5,e5,f5,g5,h5,a4,b4,c4,d4,e4,f4,g4,h4,a3,b3,c3,d3,e3,f3,g3,h3,a2,b2,c2,d2,e2,f2,g2,h2,a1,b1,c1,d1,e1,f1,g1,h1\"\n",
    "csv.write(features)\n",
    "csv.write(\"\\n\")\n",
    "idx = 0\n",
    "\n",
    "# for gameIndex, game in enumerate(embedding_split[:450]):\n",
    "for gameIndex, game in enumerate(embedding_split):\n",
    "    pi = 0\n",
    "    for idx, pos in enumerate(game):\n",
    "        csv.write(str(pos[0]))\n",
    "        csv.write(\",\")\n",
    "        csv.write(str(pos[1]))\n",
    "        \n",
    "        # number of game\n",
    "        csv.write(\",\")\n",
    "        csv.write(str(gameIndex))\n",
    "        \n",
    "        # checkpoint\n",
    "        csv.write(\",\")\n",
    "        if idx == 0:\n",
    "            csv.write(\"1\")\n",
    "        elif idx == len(game) - 1:\n",
    "            csv.write(\"1\")\n",
    "        else:\n",
    "            csv.write(\"0\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 'algo', i.e., path coloring method\n",
    "        csv.write(\",\")\n",
    "        # using opening category from A through E\n",
    "        csv.write(metadata[gameIndex]['Opening Category'])\n",
    "        # in this case the winner\n",
    "        # winner = metadata[gameIndex]['Result']\n",
    "        # winner = winner.replace('1-0', metadata[gameIndex]['White'])\n",
    "        # winner = winner.replace('0-1', metadata[gameIndex]['Black'])\n",
    "        # csv.write(winner)\n",
    "\n",
    "        # player - whose turn is it\n",
    "        csv.write(\",\")\n",
    "        if idx % 2 == 0:\n",
    "            csv.write(metadata[gameIndex]['Black'])\n",
    "        else:\n",
    "            csv.write(metadata[gameIndex]['White'])\n",
    "        \n",
    "        # age\n",
    "        csv.write(\",\")\n",
    "        csv.write(str(idx))\n",
    "        csv.write(\",\")\n",
    "        \n",
    "        # per game metadata\n",
    "        md_values = [metadata[gameIndex][k] for k in md_keys]\n",
    "        csv.write(','.join(md_values))\n",
    "        # write metadata gameIndex idx %clk and %eval\n",
    "        \n",
    "        # per move metadata\n",
    "        csv.write(',')\n",
    "        if idx < len(metadata_evals[gameIndex]):\n",
    "            csv.write(metadata_evals[gameIndex][idx])\n",
    "        csv.write(',')\n",
    "        if idx < len(metadata_clks[gameIndex]):\n",
    "            csv.write(metadata_clks[gameIndex][idx])\n",
    "        \n",
    "        for n in range(0, 64):\n",
    "            csv.write(\",\")\n",
    "            str1 = ''.join(str(e) for e in game_matrices[gameIndex][idx][n * 13: (n+1) * 13])\n",
    "            csv.write(vector_to_state(str1))\n",
    "            \n",
    "        csv.write(\"\\n\")\n",
    "    gameIndex += 1\n",
    "        \n",
    "csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap.parametric_umap import ParametricUMAP\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "dims = (8, 8, 13)\n",
    "n_components = 2\n",
    "encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=dims),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=16, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=128, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=256, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=100),\n",
    "    tf.keras.layers.Dense(units=100),\n",
    "    tf.keras.layers.Dense(units=100),\n",
    "    tf.keras.layers.Dense(units=n_components),\n",
    "])\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_fit_kwargs = {\"callbacks\": [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        min_delta=10**-2,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "    )\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass encoder network to ParametricUMAP\n",
    "reducer = ParametricUMAP(\n",
    "    verbose=True,\n",
    "    keras_fit_kwargs = keras_fit_kwargs,\n",
    "    encoder=encoder,\n",
    "    dims=dims,\n",
    "    random_state=1,\n",
    "    n_training_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embedding = reducer.fit_transform(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(reducer._history['loss'])\n",
    "ax.set_ylabel('Cross Entropy')\n",
    "ax.set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embedding_split = np.array_split(umap_embedding, np.add.accumulate([len(l) for l in game_matrices]))[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('lichess_tsne.csv', header=0, index_col=False)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x'] = umap_embedding[:,0]\n",
    "df['y'] = umap_embedding[:,1]\n",
    "df.head()\n",
    "# store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lichess_umap_seed0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8,8))\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.set_aspect(1)\n",
    "# for game in umap_embedding_split[:100]:\n",
    "#     ax.plot(game[:,0], game[:,1], '-r', alpha=0.1, color='red')\n",
    "# for game in umap_embedding_split[100:]:\n",
    "#     ax.plot(game[:,0], game[:,1], '-r', alpha=0.1, color='blue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
