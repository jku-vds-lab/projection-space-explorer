{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgn2gif import chess\n",
    "import numpy as np\n",
    "from openTSNE import TSNE\n",
    "from openTSNE.callbacks import ErrorApproximations\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import interpolate\n",
    "import re\n",
    "import pandas as pd\n",
    "from custom_chess_utils.utils import *\n",
    "from umap.parametric_umap import ParametricUMAP\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "seed = 2\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# chess_games_path = '/mnt/d/Work/CG Institute/chess/lichess data/lichess_db_standard_rated_2021-08.pgn'\n",
    "# chess_games_path = '/pse/notebooks/chess/data/lichess_db_standard_rated_2021-08_subsampled.pgn'\n",
    "chess_games_path = './data/lichess_db_standard_rated_2021-08_subsampled.pgn'\n",
    "# chess_games_path = 'data/eco_games.pgn'\n",
    "pgn_folder = 'games'\n",
    "# umap_path = 'lichess_param_umap_nodup_custom_seed'+str(seed)+'.csv'\n",
    "umap_path = 'lichess_games_seed'+str(seed)+'_no_duplicate_projection.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract individual games from PGN file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_games = extract_individual_games_from_pgn(chess_games_path, pgn_folder, lines_to_read=1500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out games without eval score or without clk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_games = get_games_with_eval_and_clk(split_games)\n",
    "print(len(split_games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keep n games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_games = 3000#99999\n",
    "split_games = split_games[:n_games]\n",
    "print(len(split_games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### store individual games as PGN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_games_as_pgn(split_games, pgn_folder)\n",
    "game_paths = [pgn_folder+'/game-{:05d}.pgn'.format(n+1) for n in range(n_games)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading games from individual PGN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_paths_checked, metadata, metadata_evals, metadata_clks, md_keys = get_metadata_from_pgns(game_paths)\n",
    "print(md_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_matrices, games_pgn = game_matrices_from_pgn(pgn_folder, game_paths_checked, first_moves_filter=None)\n",
    "print(len(game_matrices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keep opening moves only\n",
    "using the list of openings that corresponds to the lichess dataset https://github.com/niklasf/chess-openings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_df = get_eco_df('ECOs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add ECO category (A,B,C,D,E,F) to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = create_opening_categories_feature(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter games with Openings that don't exist in our ECO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_matrices, metadata, metadata_evals, metadata_clks, games_pgn = filter_unknown_ecos(eco_df, game_matrices, metadata, metadata_evals, metadata_clks, games_pgn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using eco dataframe to determine amount n of moves in the corresponding opening, cutting off each game after n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_matrices = cut_off_games_after_opening(game_matrices, eco_df, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get captured pieces throughout games and turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captures, _ = get_captures(game_matrices, games_pgn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummy csv without embedding to be able to load it as a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_split = all_zeros_embedding_shape(game_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(umap_path, md_keys, embedding_split, game_matrices, metadata, captures, metadata_evals, metadata_clks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finding duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df, drop_dup_df = find_duplicates(umap_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenate games into final data that will be projected, remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = np.concatenate(game_matrices)\n",
    "drop_dup_idx = drop_dup_df.index.array\n",
    "final_data = np.take(final_data, drop_dup_idx, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Embeddings / Projections and Writing to Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define the network, create UMAP object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (8, 8, 13)\n",
    "n_components = 2\n",
    "encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=dims),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=16, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=128, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=256, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=100),\n",
    "    tf.keras.layers.Dense(units=100),\n",
    "    tf.keras.layers.Dense(units=100),\n",
    "    tf.keras.layers.Dense(units=n_components),\n",
    "])\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_fit_kwargs = {\"callbacks\": [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        min_delta=10**-2,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "    )\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass encoder network to ParametricUMAP\n",
    "reducer = ParametricUMAP(\n",
    "    verbose=True,\n",
    "    keras_fit_kwargs = keras_fit_kwargs,\n",
    "    encoder=encoder,\n",
    "    dims=dims,\n",
    "    random_state=seed,\n",
    "    n_training_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### project using parametric UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embedding = reducer.fit_transform(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(reducer._history['loss'])\n",
    "ax.set_ylabel('Cross Entropy')\n",
    "ax.set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reshape resulting embedding into games, states, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embedding_split = reshape_embedding(umap_embedding, game_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge the embeddings with duplicate states and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = merge_embeddings_with_duplicate_states(dup_df, drop_dup_df, umap_embedding)\n",
    "concat_df.to_csv(umap_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### store the umap model for future embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducer.save('./parametric_umap_model_eco_no_duplicates_seed'+str(seed))\n",
    "encoder.save('./parametric_umap_model_eco_no_duplicates_seed'+str(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('./test_save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_reducer = ParametricUMAP(\n",
    "#     encoder=model,\n",
    "#     dims=dims,\n",
    "#     random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from umap.parametric_umap import load_ParametricUMAP\n",
    "# embedder = load_ParametricUMAP('parametric_umap_model_eco_no_duplicates_seed2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_embedding = loaded_reducer.transform(final_data.reshape(-1,8,8,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# print(pickle.format_version)\n",
    "# print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d7d79ed15a01c4499ca4e27a5c405c591f28c95808e2b7444d4034c940355b3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
